<h1>Ciberbullying Detection</h1>
<h2>Text Classification Project</h2>
<hr>
<h2>Description:</h2>
<p></p>
<p>This dataset is a collection of datasets from different sources related to the automatic detection of cyber-bullying. The data is from different social media platforms like Kaggle, Twitter, Wikipedia Talk pages, and YouTube. The data contains text and are labeled as bullying or not. The data contains different types of cyber-bullying like hate speech, aggression, insults, and toxicity. You have been provided with the twitter_parsed tweets dataset, wherein you have to classify whether the tweet is toxic or not.</p>
<h2>Problem Statement:</h2>
<p>You are provided with twitter_parsed_tweets: you have to perform a step-by-step NLP approach to identify the toxicity of the tweet, and classify the tweet in a binary value.</p>
<p>Target Variable : oh-label</p>
<p>Metric - **F1-Score**</p>

<hr>
<h2>Project structure</h2>
<h3>Project 7</h3>
<ul>
    <li>assets</li>
    <li>datasets</li>
    <li>notebooks</li>
        <p>1. cyberbullying_EDA.ipynb</p>
    <li>models</li>
        <p>model : </p>
    <li>deployment</li>
</ul>
<hr>
<p>Horacio Morales Gonz√°lez<p>
<a href="https://twitter.com/LachoMorales"><img src="https://img.shields.io/twitter/follow/LachoMorales?style=social" alt="Twitter: LachoMorales"/></a>
<a href="https://www.linkedin.com/in/hmorales1970/"><img scr="https://img.shields.io/badge/-hmorales1970-blue?style=flat-square&logo=Linkedin&logoColor=white" alt="Linkedin: hmorales1970"/></a>
